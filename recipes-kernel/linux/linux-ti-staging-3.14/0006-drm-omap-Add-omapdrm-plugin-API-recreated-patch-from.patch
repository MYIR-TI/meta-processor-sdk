From d66f20c9f0ace533990963701f5cc8794e44e1fe Mon Sep 17 00:00:00 2001
From: Hongmei Gou <h-gou@ti.com>
Date: Tue, 24 Mar 2015 00:20:09 -0400
Subject: [PATCH] drm/omap: Add omapdrm plugin API - recreated patch from
 glsdk kernel tree

---
 drivers/gpu/drm/omapdrm/omap_drv.c |  177 +++++++++++++++++++++++++++++++++++-
 drivers/gpu/drm/omapdrm/omap_drv.h |   59 ++++++++++++
 drivers/gpu/drm/omapdrm/omap_gem.c |   95 +++++++++++++++++++
 include/uapi/drm/omap_drm.h        |   10 +-
 4 files changed, 332 insertions(+), 9 deletions(-)

diff --git a/drivers/gpu/drm/omapdrm/omap_drv.c b/drivers/gpu/drm/omapdrm/omap_drv.c
index 15e4fe5..59f8d13 100644
--- a/drivers/gpu/drm/omapdrm/omap_drv.c
+++ b/drivers/gpu/drm/omapdrm/omap_drv.c
@@ -30,11 +30,24 @@
 #define DRIVER_MINOR		0
 #define DRIVER_PATCHLEVEL	0
 
+struct drm_device *drm_device;
+
 static int num_crtc = CONFIG_DRM_OMAP_NUM_CRTCS;
 
 MODULE_PARM_DESC(num_crtc, "Number of overlays to use as CRTCs");
 module_param(num_crtc, int, 0600);
 
+/* TODO: think about how to handle more than one plugin.. ie. some ops
+ * me might want to stop on the first plugin that doesn't return an
+ * error, etc..
+ */
+LIST_HEAD(plugin_list);
+
+/* keep track of whether we are already loaded.. we may need to call
+ * plugin's load() if they register after we are already loaded
+ */
+static __read_mostly bool loaded = false;
+
 /*
  * mode config funcs
  */
@@ -360,6 +373,27 @@ static int ioctl_set_param(struct drm_device *dev, void *data,
 	return 0;
 }
 
+static int ioctl_get_base(struct drm_device *dev, void *data,
+		struct drm_file *file_priv)
+{
+	struct drm_omap_get_base *args = data;
+	struct omap_drm_plugin *plugin;
+
+	/* be safe: */
+	args->plugin_name[ARRAY_SIZE(args->plugin_name) - 1] = '\0';
+
+	DBG("%p: plugin_name=%s", dev, args->plugin_name);
+
+	list_for_each_entry(plugin, &plugin_list, list) {
+		if (!strcmp(args->plugin_name, plugin->name)) {
+			args->ioctl_base = plugin->ioctl_base;
+			return 0;
+		}
+	}
+
+	return -EINVAL;
+}
+
 static int ioctl_gem_new(struct drm_device *dev, void *data,
 		struct drm_file *file_priv)
 {
@@ -438,10 +472,11 @@ static int ioctl_gem_info(struct drm_device *dev, void *data,
 	return ret;
 }
 
-static const struct drm_ioctl_desc ioctls[DRM_COMMAND_END - DRM_COMMAND_BASE] = {
+static struct drm_ioctl_desc ioctls[DRM_COMMAND_END - DRM_COMMAND_BASE] = {
 	DRM_IOCTL_DEF_DRV(OMAP_GET_PARAM, ioctl_get_param, DRM_UNLOCKED|DRM_AUTH),
 	DRM_IOCTL_DEF_DRV(OMAP_SET_PARAM, ioctl_set_param, DRM_UNLOCKED|DRM_AUTH|DRM_MASTER|DRM_ROOT_ONLY),
-	DRM_IOCTL_DEF_DRV(OMAP_GEM_NEW, ioctl_gem_new, DRM_UNLOCKED|DRM_AUTH),
+	DRM_IOCTL_DEF_DRV(OMAP_GET_BASE, ioctl_get_base, DRM_UNLOCKED|DRM_AUTH|DRM_RENDER_ALLOW),
+        DRM_IOCTL_DEF_DRV(OMAP_GEM_NEW, ioctl_gem_new, DRM_UNLOCKED|DRM_AUTH),
 	DRM_IOCTL_DEF_DRV(OMAP_GEM_CPU_PREP, ioctl_gem_cpu_prep, DRM_UNLOCKED|DRM_AUTH),
 	DRM_IOCTL_DEF_DRV(OMAP_GEM_CPU_FINI, ioctl_gem_cpu_fini, DRM_UNLOCKED|DRM_AUTH),
 	DRM_IOCTL_DEF_DRV(OMAP_GEM_INFO, ioctl_gem_info, DRM_UNLOCKED|DRM_AUTH),
@@ -465,10 +500,13 @@ static int dev_load(struct drm_device *dev, unsigned long flags)
 {
 	struct omap_drm_platform_data *pdata = dev->dev->platform_data;
 	struct omap_drm_private *priv;
+	struct omap_drm_plugin *plugin;
 	int ret;
 
 	DBG("load: dev=%p", dev);
 
+	drm_device = dev;
+
 	priv = kzalloc(sizeof(*priv), GFP_KERNEL);
 	if (!priv)
 		return -ENOMEM;
@@ -507,6 +545,12 @@ static int dev_load(struct drm_device *dev, unsigned long flags)
 
 	drm_kms_helper_poll_init(dev);
 
+	loaded = true;
+
+	list_for_each_entry(plugin, &plugin_list, list) {
+		ret = plugin->load(dev, flags);
+	}
+
 	return 0;
 }
 
@@ -514,9 +558,15 @@ static int dev_unload(struct drm_device *dev)
 {
 	struct omap_drm_private *priv = dev->dev_private;
 	int i;
+	struct omap_drm_plugin *plugin;
+	int ret;
 
 	DBG("unload: dev=%p", dev);
 
+	list_for_each_entry(plugin, &plugin_list, list) {
+		ret = plugin->unload(dev);
+	}
+
 	drm_kms_helper_poll_fini(dev);
 
 	if (priv->fbdev)
@@ -539,15 +589,37 @@ static int dev_unload(struct drm_device *dev)
 
 	dev_set_drvdata(dev->dev, NULL);
 
+	loaded = false;
+
 	return 0;
 }
 
 static int dev_open(struct drm_device *dev, struct drm_file *file)
 {
-	file->driver_priv = NULL;
+	struct omap_drm_plugin *plugin;
+	bool found_pvr = false;
+	int ret;
+
+	file->driver_priv = kzalloc(sizeof(void *) * MAX_MAPPERS, GFP_KERNEL);
 
 	DBG("open: dev=%p, file=%p", dev, file);
 
+	list_for_each_entry(plugin, &plugin_list, list) {
+		if (!strcmp(DRIVER_NAME "_pvr", plugin->name)) {
+			found_pvr = true;
+			break;
+		}
+	}
+
+	if (!found_pvr) {
+		DBG("open: PVR submodule not loaded.. let's try now");
+		request_module(DRIVER_NAME "_pvr");
+	}
+
+	list_for_each_entry(plugin, &plugin_list, list) {
+		ret = plugin->open(dev, file);
+	}
+
 	return 0;
 }
 
@@ -608,9 +680,15 @@ static void dev_preclose(struct drm_device *dev, struct drm_file *file)
 {
 	struct omap_drm_private *priv = dev->dev_private;
 	int i;
+	struct omap_drm_plugin *plugin;
+	int ret;
 
 	DBG("preclose: dev=%p", dev);
 
+	list_for_each_entry(plugin, &plugin_list, list) {
+		ret = plugin->release(dev, file);
+	}
+
 	/*
 	 * Flush crtcs to finish any pending work.
 	 * Note: this may not be correct if there are multiple applications
@@ -620,6 +698,8 @@ static void dev_preclose(struct drm_device *dev, struct drm_file *file)
 	 */
 	for (i = 0; i < priv->num_crtcs; i++)
 		omap_crtc_flush(priv->crtcs[i]);
+
+	kfree(file->driver_priv);
 }
 
 static void dev_postclose(struct drm_device *dev, struct drm_file *file)
@@ -629,8 +709,8 @@ static void dev_postclose(struct drm_device *dev, struct drm_file *file)
 
 static const struct vm_operations_struct omap_gem_vm_ops = {
 	.fault = omap_gem_fault,
-	.open = drm_gem_vm_open,
-	.close = drm_gem_vm_close,
+	.open = omap_gem_vm_open,
+	.close = omap_gem_vm_close,
 };
 
 static const struct file_operations omapdriver_fops = {
@@ -684,6 +764,93 @@ static struct drm_driver omap_drm_driver = {
 		.patchlevel = DRIVER_PATCHLEVEL,
 };
 
+int omap_drm_register_plugin(struct omap_drm_plugin *plugin)
+{
+	struct drm_device *dev = drm_device;
+	static int ioctl_base = DRM_OMAP_NUM_IOCTLS;
+	int i;
+
+	DBG("register plugin: %p (%s)", plugin, plugin->name);
+
+	plugin->ioctl_base = ioctl_base;
+
+	list_add_tail(&plugin->list, &plugin_list);
+
+	/* register the plugin's ioctl's */
+	for (i = 0; i < plugin->num_ioctls; i++) {
+		int nr = i + ioctl_base;
+
+		/* check for out of bounds ioctl nr or
+		   already registered ioctl */
+		if (nr > ARRAY_SIZE(ioctls) || ioctls[nr].func) {
+			dev_err(dev->dev, "invalid ioctl: %d (nr=%d)\n", i, nr);
+			return -EINVAL;
+		}
+
+		DBG("register ioctl: %d %08x", nr, plugin->ioctls[i].cmd);
+
+		ioctls[nr] = plugin->ioctls[i];
+
+		if (nr >= omap_drm_driver.num_ioctls)
+			omap_drm_driver.num_ioctls = nr + 1;
+
+	}
+
+	ioctl_base += plugin->num_ioctls;
+
+	if (loaded)
+		plugin->load(dev, 0);
+
+	return 0;
+}
+EXPORT_SYMBOL(omap_drm_register_plugin);
+
+int omap_drm_unregister_plugin(struct omap_drm_plugin *plugin)
+{
+	list_del(&plugin->list);
+	/* TODO remove ioctl fxns */
+	return 0;
+}
+EXPORT_SYMBOL(omap_drm_unregister_plugin);
+
+static int nmappers = 0;
+
+/* create buffer mapper id, to access per-mapper private data.  See
+ * omap_gem_{get,set}_priv().
+ */
+int omap_drm_register_mapper(void)
+{
+	if (nmappers >= MAX_MAPPERS)
+		return -ENOMEM;
+	return nmappers++;
+}
+EXPORT_SYMBOL(omap_drm_register_mapper);
+
+/* retire a mapper id, previously acquired from omap_drm_register_mapper()
+ */
+void omap_drm_unregister_mapper(int mapper_id)
+{
+	/* currently no-op.. */
+}
+EXPORT_SYMBOL(omap_drm_unregister_mapper);
+
+void *omap_drm_file_priv(struct drm_file *file, int mapper_id)
+{
+	BUG_ON((mapper_id >= MAX_MAPPERS) || (mapper_id < 0));
+	if (file->driver_priv)
+		return ((void **)file->driver_priv)[mapper_id];
+	return NULL;
+}
+EXPORT_SYMBOL(omap_drm_file_priv);
+
+void omap_drm_file_set_priv(struct drm_file *file, int mapper_id, void *priv)
+{
+	BUG_ON((mapper_id >= MAX_MAPPERS) || (mapper_id < 0));
+	((void **)file->driver_priv)[mapper_id] = priv;
+}
+EXPORT_SYMBOL(omap_drm_file_set_priv);
+
+
 static int pdev_probe(struct platform_device *device)
 {
 	int r;
diff --git a/drivers/gpu/drm/omapdrm/omap_drv.h b/drivers/gpu/drm/omapdrm/omap_drv.h
index 2ab710a..e03a2ab 100644
--- a/drivers/gpu/drm/omapdrm/omap_drv.h
+++ b/drivers/gpu/drm/omapdrm/omap_drv.h
@@ -311,4 +311,63 @@ fail:
 	return -ENOENT;
 }
 
+/****** PLUGIN API specific ******/
+
+/* interface that plug-in drivers (for now just PVR) can implement */
+struct omap_drm_plugin {
+	const char *name;
+
+	/* drm functions */
+	int (*load)(struct drm_device *dev, unsigned long flags);
+	int (*unload)(struct drm_device *dev);
+	int (*open)(struct drm_device *dev, struct drm_file *file);
+	int (*release)(struct drm_device *dev, struct drm_file *file);
+
+	struct drm_ioctl_desc *ioctls;
+	int num_ioctls;
+	int ioctl_base;
+
+	struct list_head list;  /* note, this means struct can't be const.. */
+};
+
+int omap_drm_register_plugin(struct omap_drm_plugin *plugin);
+int omap_drm_unregister_plugin(struct omap_drm_plugin *plugin);
+
+int omap_drm_register_mapper(void);
+void omap_drm_unregister_mapper(int id);
+
+void *omap_drm_file_priv(struct drm_file *file, int mapper_id);
+void omap_drm_file_set_priv(struct drm_file *file, int mapper_id, void *priv);
+
+void *omap_gem_priv(struct drm_gem_object *obj, int mapper_id);
+void omap_gem_set_priv(struct drm_gem_object *obj, int mapper_id, void *priv);
+void omap_gem_vm_open(struct vm_area_struct *vma);
+void omap_gem_vm_close(struct vm_area_struct *vma);
+
+/* for external plugin buffers wrapped as GEM object (via. omap_gem_new_ext())
+ * a vm_ops struct can be provided to get callback notification of various
+ * events..
+ */
+struct omap_gem_vm_ops {
+	void (*open)(struct vm_area_struct *area);
+	void (*close)(struct vm_area_struct *area);
+	/*maybe: int (*fault)(struct vm_area_struct *vma,
+	  struct vm_fault *vmf)*/
+
+	/* note: mmap isn't expected to do anything. it is just to allow buffer
+	 * allocate to update it's own internal state
+	 */
+	void (*mmap)(struct file *, struct vm_area_struct *);
+};
+
+struct drm_gem_object *omap_gem_new_ext(struct drm_device *dev,
+		union omap_gem_size gsize, uint32_t flags,
+		dma_addr_t paddr, struct page **pages,
+		struct omap_gem_vm_ops *ops);
+
+void omap_gem_op_update(void);
+int omap_gem_set_sync_object(struct drm_gem_object *obj, void *syncobj);
+/*********************************/
+
+
 #endif /* __OMAP_DRV_H__ */
diff --git a/drivers/gpu/drm/omapdrm/omap_gem.c b/drivers/gpu/drm/omapdrm/omap_gem.c
index eaff3b2..36ff7e9 100644
--- a/drivers/gpu/drm/omapdrm/omap_gem.c
+++ b/drivers/gpu/drm/omapdrm/omap_gem.c
@@ -117,6 +117,18 @@ struct omap_gem_object {
 		uint32_t read_pending;
 		uint32_t read_complete;
 	} *sync;
+
+	struct omap_gem_vm_ops *ops;
+
+	/**
+	 * per-mapper private data..
+	 *
+	 * TODO maybe there can be a more flexible way to store per-mapper
+	 * data.. for now I just keep it simple, and since this is only
+	 * accessible externally via omap_gem_priv()/omap_get_set_priv()
+	 */
+	void *priv[MAX_MAPPERS];
+
 };
 
 static int get_pages(struct drm_gem_object *obj, struct page ***pages);
@@ -304,6 +316,7 @@ uint32_t omap_gem_flags(struct drm_gem_object *obj)
 {
 	return to_omap_bo(obj)->flags;
 }
+EXPORT_SYMBOL(omap_gem_flags);
 
 /** get mmap offset */
 static uint64_t mmap_offset(struct drm_gem_object *obj)
@@ -333,6 +346,7 @@ uint64_t omap_gem_mmap_offset(struct drm_gem_object *obj)
 	mutex_unlock(&obj->dev->struct_mutex);
 	return offset;
 }
+EXPORT_SYMBOL(omap_gem_mmap_offset);
 
 /** get mmap size */
 size_t omap_gem_mmap_size(struct drm_gem_object *obj)
@@ -365,6 +379,7 @@ int omap_gem_tiled_size(struct drm_gem_object *obj, uint16_t *w, uint16_t *h)
 	}
 	return -EINVAL;
 }
+EXPORT_SYMBOL(omap_gem_tiled_size);
 
 /* Normal handling for the case of faulting in non-tiled buffers */
 static int fault_1d(struct drm_gem_object *obj,
@@ -597,6 +612,9 @@ int omap_gem_mmap_obj(struct drm_gem_object *obj,
 		vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
 	}
 
+	if (omap_obj->ops && omap_obj->ops->mmap)
+		omap_obj->ops->mmap(obj->filp, vma);
+
 	return 0;
 }
 
@@ -809,6 +827,7 @@ fail:
 
 	return ret;
 }
+EXPORT_SYMBOL(omap_gem_get_paddr);
 
 /* Release physical address, when DMA is no longer being performed.. this
  * could potentially unpin and unmap buffers from TILER
@@ -841,6 +860,7 @@ fail:
 	mutex_unlock(&obj->dev->struct_mutex);
 	return ret;
 }
+EXPORT_SYMBOL(omap_gem_put_paddr);
 
 /* Get rotated scanout address (only valid if already pinned), at the
  * specified orientation and x,y offset from top-left corner of buffer
@@ -871,6 +891,7 @@ int omap_gem_tiled_stride(struct drm_gem_object *obj, uint32_t orient)
 		ret = tiler_stride(gem2fmt(omap_obj->flags), orient);
 	return ret;
 }
+EXPORT_SYMBOL(omap_gem_tiled_stride);
 
 /* acquire pages when needed (for example, for DMA where physically
  * contiguous buffer is not required
@@ -920,6 +941,7 @@ int omap_gem_get_pages(struct drm_gem_object *obj, struct page ***pages,
 	mutex_unlock(&obj->dev->struct_mutex);
 	return ret;
 }
+EXPORT_SYMBOL(omap_gem_get_pages);
 
 /* release pages when DMA no longer being performed */
 int omap_gem_put_pages(struct drm_gem_object *obj)
@@ -930,6 +952,7 @@ int omap_gem_put_pages(struct drm_gem_object *obj)
 	 */
 	return 0;
 }
+EXPORT_SYMBOL(omap_gem_put_pages);
 
 /* Get kernel virtual address for CPU access.. this more or less only
  * exists for omap_fbdev.  This should be called with struct_mutex
@@ -1125,17 +1148,20 @@ void omap_gem_op_update(void)
 	sync_op_update();
 	spin_unlock(&sync_lock);
 }
+EXPORT_SYMBOL(omap_gem_op_update);
 
 /* mark the start of read and/or write operation */
 int omap_gem_op_start(struct drm_gem_object *obj, enum omap_gem_op op)
 {
 	return sync_op(obj, op, true);
 }
+EXPORT_SYMBOL(omap_gem_op_start);
 
 int omap_gem_op_finish(struct drm_gem_object *obj, enum omap_gem_op op)
 {
 	return sync_op(obj, op, false);
 }
+EXPORT_SYMBOL(omap_gem_op_finish);
 
 static DECLARE_WAIT_QUEUE_HEAD(sync_event);
 
@@ -1190,6 +1216,7 @@ int omap_gem_op_sync(struct drm_gem_object *obj, enum omap_gem_op op)
 	}
 	return ret;
 }
+EXPORT_SYMBOL(omap_gem_op_sync);
 
 /* call fxn(arg), either synchronously or asynchronously if the op
  * is currently blocked..  fxn() can be called from any context
@@ -1236,6 +1263,7 @@ int omap_gem_op_async(struct drm_gem_object *obj, enum omap_gem_op op,
 
 	return 0;
 }
+EXPORT_SYMBOL(omap_gem_op_async);
 
 /* special API so PVR can update the buffer to use a sync-object allocated
  * from it's sync-obj heap.  Only used for a newly allocated (from PVR's
@@ -1273,6 +1301,7 @@ unlock:
 	spin_unlock(&sync_lock);
 	return ret;
 }
+EXPORT_SYMBOL(omap_gem_set_sync_object);
 
 /* don't call directly.. called from GEM core when it is time to actually
  * free the object..
@@ -1489,3 +1518,69 @@ void omap_gem_deinit(struct drm_device *dev)
 	 */
 	kfree(usergart);
 }
+
+/****** PLUGIN API specific ******/
+
+/* This constructor is mainly to give plugins a way to wrap their
+ * own allocations
+ */
+struct drm_gem_object *omap_gem_new_ext(struct drm_device *dev,
+		union omap_gem_size gsize, uint32_t flags,
+		dma_addr_t paddr, struct page **pages,
+		struct omap_gem_vm_ops *ops)
+{
+	struct drm_gem_object *obj;
+
+	BUG_ON((flags & OMAP_BO_TILED) && !pages);
+
+	if (paddr)
+		flags |= OMAP_BO_DMA;
+
+	obj = omap_gem_new(dev, gsize, flags | OMAP_BO_EXT_MEM);
+	if (obj) {
+		struct omap_gem_object *omap_obj = to_omap_bo(obj);
+		omap_obj->paddr = paddr;
+		omap_obj->pages = pages;
+		omap_obj->ops = ops;
+	}
+	return obj;
+}
+EXPORT_SYMBOL(omap_gem_new_ext);
+
+void omap_gem_vm_open(struct vm_area_struct *vma)
+{
+	struct drm_gem_object *obj = vma->vm_private_data;
+	struct omap_gem_object *omap_obj = to_omap_bo(obj);
+
+	if (omap_obj->ops && omap_obj->ops->open)
+		omap_obj->ops->open(vma);
+	else
+		drm_gem_vm_open(vma);
+
+}
+
+void omap_gem_vm_close(struct vm_area_struct *vma)
+{
+	struct drm_gem_object *obj = vma->vm_private_data;
+	struct omap_gem_object *omap_obj = to_omap_bo(obj);
+
+	if (omap_obj->ops && omap_obj->ops->close)
+		omap_obj->ops->close(vma);
+	else
+		drm_gem_vm_close(vma);
+
+}
+
+void *omap_gem_priv(struct drm_gem_object *obj, int mapper_id)
+{
+	BUG_ON((mapper_id >= MAX_MAPPERS) || (mapper_id < 0));
+	return to_omap_bo(obj)->priv[mapper_id];
+}
+EXPORT_SYMBOL(omap_gem_priv);
+
+void omap_gem_set_priv(struct drm_gem_object *obj, int mapper_id, void *priv)
+{
+	BUG_ON((mapper_id >= MAX_MAPPERS) || (mapper_id < 0));
+	to_omap_bo(obj)->priv[mapper_id] = priv;
+}
+EXPORT_SYMBOL(omap_gem_set_priv);
diff --git a/include/uapi/drm/omap_drm.h b/include/uapi/drm/omap_drm.h
index 1d0b117..5292b93 100644
--- a/include/uapi/drm/omap_drm.h
+++ b/include/uapi/drm/omap_drm.h
@@ -33,6 +33,12 @@ struct drm_omap_param {
 	uint64_t value;			/* in (set_param), out (get_param) */
 };
 
+struct drm_omap_get_base {
+	char plugin_name[64];           /* in */
+	uint32_t ioctl_base;            /* out */
+	uint32_t __pad;
+};
+
 #define OMAP_BO_SCANOUT		0x00000001	/* scanout capable (phys contiguous) */
 #define OMAP_BO_CACHE_MASK	0x00000006	/* cache type mask, see cache modes */
 #define OMAP_BO_TILED_MASK	0x00000f00	/* tiled mapping mask, see tiled modes */
@@ -101,9 +107,7 @@ struct drm_omap_gem_info {
 
 #define DRM_OMAP_GET_PARAM		0x00
 #define DRM_OMAP_SET_PARAM		0x01
-/* placeholder for plugin-api
 #define DRM_OMAP_GET_BASE		0x02
-*/
 #define DRM_OMAP_GEM_NEW		0x03
 #define DRM_OMAP_GEM_CPU_PREP		0x04
 #define DRM_OMAP_GEM_CPU_FINI		0x05
@@ -112,9 +116,7 @@ struct drm_omap_gem_info {
 
 #define DRM_IOCTL_OMAP_GET_PARAM	DRM_IOWR(DRM_COMMAND_BASE + DRM_OMAP_GET_PARAM, struct drm_omap_param)
 #define DRM_IOCTL_OMAP_SET_PARAM	DRM_IOW (DRM_COMMAND_BASE + DRM_OMAP_SET_PARAM, struct drm_omap_param)
-/* placeholder for plugin-api
 #define DRM_IOCTL_OMAP_GET_BASE		DRM_IOWR(DRM_COMMAND_BASE + DRM_OMAP_GET_BASE, struct drm_omap_get_base)
-*/
 #define DRM_IOCTL_OMAP_GEM_NEW		DRM_IOWR(DRM_COMMAND_BASE + DRM_OMAP_GEM_NEW, struct drm_omap_gem_new)
 #define DRM_IOCTL_OMAP_GEM_CPU_PREP	DRM_IOW (DRM_COMMAND_BASE + DRM_OMAP_GEM_CPU_PREP, struct drm_omap_gem_cpu_prep)
 #define DRM_IOCTL_OMAP_GEM_CPU_FINI	DRM_IOW (DRM_COMMAND_BASE + DRM_OMAP_GEM_CPU_FINI, struct drm_omap_gem_cpu_fini)
-- 
1.7.9.5

